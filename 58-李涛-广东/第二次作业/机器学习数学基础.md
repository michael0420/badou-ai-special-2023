### 向量

向量是具有大小和方向的量，可以用有序数对或有序数列表示，并且支持加法和数乘运算

### 线性变换

线性变换是保持向量空间中加法和数乘运算不变的向量映射，可用矩阵表示

1. T(V+W) = T(V)+T(W) 
2. T(CV) = CT(V)

这两个等式是线性变换的基本性质，其中 T 表示线性变换，V 和 W 是向量，C 是标量。

第一个等式表示线性变换 T 对向量空间中的向量 V+W 的作用等于分别对 V 和 W 进行线性变换后的结果相加。

第二个等式表示线性变换 T 对向量空间中的标量乘以向量 CV 的作用等于将标量 C 乘以线性变换 T 对向量 V 的作用。

### 矩阵

矩阵是由数字按照矩形排列而成的方阵，用于表示线性变换、解线性方程组等数学运算中的数据结构

**矩阵加减法：**两个矩阵相加或相减，需要满足两个矩阵的列数和行数一致。

**加法交换律：**A + B = B + A

**矩阵乘法：**两个矩阵A和B相乘，需要满足A的列数等于B的行数

A * B 不等于 B * A

**单位矩阵：**单位矩阵是一个n×n矩阵，从左到右的对角线上的元素是1，其余元素都为0。

如果A是n×n矩阵，I是单位矩阵，则AI= A, IA = A，单位矩阵在矩阵乘法中的作用相当于数字1，1 乘任何数都等于乘数本身

**逆矩阵：**矩阵A的逆矩阵记作A-1， A A-1= A-1 A= I，I是单位矩阵

**奇异矩阵：**当一个矩阵没有逆矩阵的时候，称该矩阵为奇异矩阵。当且仅当一个矩阵的行列式为零时，该矩阵是奇异矩阵。

**矩阵的转置：**简单地说，矩阵的转置就是行列互换

转置运算特性：

![image-20231024233035075](C:\Users\28633\AppData\Roaming\Typora\typora-user-images\image-20231024233035075.png)

**对称矩阵**:

如果一个矩阵转置后等于原矩阵，那么这个矩阵称为对称矩阵,一个矩阵转置和这个矩阵的乘积就是一个对称矩阵。

### 欧氏变换

欧氏变换由两部分组成：旋转 平移    a' = Ra + t

欧氏变换可以由平移和旋转两个基本的刚体运动组成。平移是指将物体沿着某一方向移动一定的距离，不改变物体的形状和大小；而旋转是指将物体绕着某一点或某一轴旋转一定的角度，同样也不改变物体的形状和大小。

在欧几里得空间中，任何一个欧氏变换都可以表示为一个旋转矩阵和一个平移向量的组合。具体来说，对于一个三维空间中的欧氏变换，可以用一个 3×3 的旋转矩阵 *R* 和一个 3×1 的平移向量 *t* 表示。其中，旋转矩阵 �*R* 描述了物体的旋转变换，平移向量 *t* 描述了物体的平移变换。这种表示方法称为欧氏变换矩阵

因此，欧氏变换中的旋转和平移可以分别看作是物体的旋转和平移，通过这两个基本的刚体运动可以描述任何欧氏变换，从而实现对物体的变换和操作

### 齐次坐标

齐次坐标就是用N+1维来代表N维坐标,我们可以在一个2D坐标末尾加上一个额外的变量w来形成2D齐次坐标

因此，一个点(X,Y)在齐次坐标里面变成了（x,y,w），并且有  X = x/w    Y = y/w   

例如：（1，2）的齐次坐标可以表示为（1，2，1）

如果点（1，2）移动到无限远处，在笛卡尔坐标下它变为(∞,∞)，然后它的齐次坐标表示为（1，2，0），因为(1/0, 2/0) = (∞,∞)，我们可以不用”∞"来表示一个无穷远处的点了

### 导数&偏导数

**导数（微分）：**是代表函数（曲线）的**斜率**，是描述函数（曲线）**变化快慢的量**，同时曲线的极大值点也可以使用导数来判断，即极大值点的导数为0，此时斜率为零

**偏导数：**是指在多元函数的情况下，对其每个变量进行求导，求导时，把其他变量看做常量进行处理，物理意义就是查看这一个变量在其他情况不变的情况下对函数的影响程度。

![image-20231025000325387](C:\Users\28633\AppData\Roaming\Typora\typora-user-images\image-20231025000325387.png)

### 梯度

梯度的本意是一个**向量**（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大（为该梯度的模）简而言之，对多元函数的各个自变量求偏导数，并把求得的这些偏导数写成向量形式，就是梯度

梯度在优化问题中经常被用作搜索方向，因为它指向了函数值增加最快的方向，可以帮助我们快速找到函数的极值点。例如，在梯度下降算法中，我们以负梯度方向作为下降的方向，以迭代的方式逐步接近函数的极小值点。

![image-20231025000922203](C:\Users\28633\AppData\Roaming\Typora\typora-user-images\image-20231025000922203.png)

**梯度下降法：是一种寻找函数极小值的方法。**

该方法最普通的做法是：在已知**参数当前值**的情况下，按当前点对应的**梯度向量的反方向**，并按事先给定好的**步长**大小，对参数进行调整。

按如上方法对参数做出多次调整之后，函数就会逼近一个极小值

![image-20231025001515609](C:\Users\28633\AppData\Roaming\Typora\typora-user-images\image-20231025001515609.png)

**梯度下降法存在的问题：**

1.参数调整缓慢

2.收敛于局部最小值

![image-20231025001637966](C:\Users\28633\AppData\Roaming\Typora\typora-user-images\image-20231025001637966.png)

### 概率学基础

概率学是数学的一个分支，研究随机事件和随机现象的规律性及其数学描述。它是统计学的基础，也应用于各种领域，如自然科学、工程、经济学等。

以下是概率学的一些基础概念：

1. 随机试验：具有不确定结果的实验称为随机试验，例如掷硬币、抛骰子等。
2. 样本空间：随机试验所有可能结果的集合称为样本空间，通常用 S 表示。
3. 事件：样本空间的子集称为事件，表示某些结果的集合。
4. 概率：概率是对事件发生可能性的度量，用一个介于 0 和 1 之间的数值表示。常用 P(A) 表示事件 A 的概率。
5. 概率公理：概率满足一些基本的公理，如非负性（概率不为负）、规范性（样本空间的概率为 1）、可列可加性等。
6. 条件概率：条件概率指在已知某一事件发生的条件下，另一事件发生的概率。记作 P(A|B)，表示在事件 B 发生的条件下事件 A 发生的概率。
7. 独立事件：如果事件 A 的发生与事件 B 的发生没有关系，即 P(A|B) = P(A)，则称事件 A 和事件 B 是独立事件。
8. 事件的运算：概率论中有一些基本的事件运算，如并、交、差、补等，可以通过这些运算来计算复杂事件的概率。
9. 随机变量：随机变量是对随机试验结果的数值化描述。它可以是离散型（取有限或可数个值）或连续型（取连续范围内的值）。
10. 概率分布：概率分布描述了随机变量取不同值的概率情况，如离散型随机变量的概率质量函数和连续型随机变量的概率密度函数。

**事件运算定律**

这些是概率学的一些基础概念，它们为我们理解随机事件和随机现象的规律性提供了数学工具和方法。

1. 并事件的概率：对于两个事件 A 和 B，它们的并事件（表示为 A ∪ B）的概率可以通过以下公式计算：

   P(A ∪ B) = P(A) + P(B) - P(A ∩ B)

   其中 P(A) 表示事件 A 的概率，P(B) 表示事件 B 的概率，P(A ∩ B) 表示事件 A 和事件 B 同时发生的概率。

2. 交事件的概率：对于两个事件 A 和 B，它们的交事件（表示为 A ∩ B）的概率可以通过以下公式计算：

   P(A ∩ B) = P(A) * P(B|A)

   其中 P(A) 表示事件 A 的概率，P(B|A) 表示在事件 A 发生的条件下事件 B 发生的概率。

3. 差事件的概率：对于两个事件 A 和 B，它们的差事件（表示为 A - B，即事件 A 发生而事件 B 不发生）的概率可以通过以下公式计算：

   P(A - B) = P(A) - P(A ∩ B)

   其中 P(A) 表示事件 A 的概率，P(A ∩ B) 表示事件 A 和事件 B 同时发生的概率。

4. 互斥事件的概率：如果两个事件 A 和 B 互斥（即事件 A 和事件 B 不可能同时发生），则它们的交事件的概率为零，即 P(A ∩ B) = 0。在这种情况下，并事件的概率可以简化为：

   P(A ∪ B) = P(A) + P(B)

   即并事件的概率等于事件 A 的概率加上事件 B 的概率。

这些事件运算定律是概率论中的基本工具，可以帮助我们计算和推导各种复杂事件的概率。根据这些定律，我们可以进行事件的组合、分解和计算，从而得到所需的概率结果。

![image-20231025002515437](C:\Users\28633\AppData\Roaming\Typora\typora-user-images\image-20231025002515437.png)

**独立性**

设A，B为随机事件，若同时发生的概率等于各自发生的概率的乘积，则A，B**相互独立**

P（AB） = P(A) P(B)

**离散**

离散就是不连续

**数学期望（均值**）：表示一件事平均发生的概率，记为E(x), E(x) = x1p1+x2p2+...+ xnpn

数学期望是概率论和统计学中的一个重要概念，用于描述随机变量的平均值。它是对随机变量可能取值的加权平均，其中每个值的权重是其发生的概率。

对于**离散型随机变量**，数学期望可以通过将每个可能取值乘以其对应的概率，并将所有结果相加得到。数学期望的

计算公式如下：

E(X) = x₁*p₁ + x₂*p₂ + ... + xₙ*pₙ

其中，X表示随机变量，x₁、x₂、...、xₙ表示随机变量可能取到的值，p₁、p₂、...、pₙ表示对应值的概率。

对于**连续型随机变量**，数学期望可以通过对其概率密度函数进行积分来计算。

数学期望的计算公式如下：

E(X) = ∫[a,b] x*f(x) dx

其中，X表示随机变量，a和b表示随机变量可能取值的范围，f(x)表示随机变量的概率密度函数。

**总结：**数学期望可以理解为在大量重复试验中，随机变量的平均表现。它是衡量随机变量集中趋势的一个指标，可以帮助我们预测或评估随机事件的平均结果

**方差：**用来刻画随机变量x和数学期望E(x)之间的偏离程度，记做D(x)。

**标准差（均方差）：**标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。

**正态分布（高斯分布）**

**正态分布：**若随机变量X服从一个数学期望为μ、方差为σ^2的正态分布，记为N(μ，σ^2)。μ决定了其位置（中心线），其标准差σ决定了分布的幅度（胖瘦）。

**标准正态分布：**当μ = 0，σ = 1时的正态分布是标准正态分布

![image-20231025223623105](C:\Users\28633\AppData\Roaming\Typora\typora-user-images\image-20231025223623105.png)

### **熵**

物理学上，是“混乱” 程度的量度。

系统越有序，熵值越低；系统越混乱或者分散，熵值越高。

熵是信息论中的一个概念，用于衡量随机事件的不确定性或信息量。它是对随机事件发生概率分布的一种度量。

在信息论中，熵可以用来描述信息的平均编码长度。对于一个离散型随机变量X，其熵H(X)的

**计算公式如下：**

H(X) = -∑[i=1,n] p(xᵢ) * log₂(p(xᵢ))

其中，xᵢ表示随机变量X可能取到的每个值，p(xᵢ)表示对应值的概率。

**熵的单位通常以比特（bit）或香农（Shannon）为基础进行衡量**。熵越高，表示随机变量的不确定性或信息量越大；熵越低，表示随机变量的不确定性或信息量越小。

**熵具有以下特性：**

1. 熵是非负的，即H(X) ≥ 0。
2. 当且仅当所有可能取值的概率相等时，熵达到最大值，表示最大的不确定性。
3. 当且仅当某个值的概率为1，其他值的概率为0时，熵达到最小值，表示最小的不确定性。

熵在信息论中有广泛的应用，例如数据压缩、密码学、通信系统等领域。通过熵的计算，我们可以了解到信息源的不确定性程度，并为设计有效的编码和通信系统提供理论依据。



